{
  "llm_judge_codet5-770m_humaneval": {
    "method": "llm_judge",
    "model": "codet5-770m",
    "dataset": "humaneval",
    "total_problems": 159,
    "total_ranking_files": 159,
    "metrics": {
      "pass_at_1": 0.11320754716981132,
      "pass_at_5": 0.20125786163522014,
      "pass_at_10": 0.27044025157232704,
      "pass_at_20": 0.32075471698113206,
      "pass_at_50": 0.36477987421383645,
      "pass_at_100": 0.4025157232704403,
      "mrr": 0.1577935174281929,
      "ndcg_at_5": 0.10075533307742976,
      "ndcg_at_10": 0.11131240745758626,
      "ndcg_at_20": 0.1217120736198278,
      "avg_first_correct_position": 66.49685534591195,
      "median_first_correct_position": 101.0,
      "success_rate": 0.4025157232704403,
      "pass_at_2": 0.1320754716981132
    },
    "execution_summary": {
      "problems_with_passing_candidates": 64,
      "total_passing_candidates": 1699,
      "total_candidates": 15900
    }
  },
  "llm_judge_codet5-770m_mbpp": {
    "method": "llm_judge",
    "model": "codet5-770m",
    "dataset": "mbpp",
    "total_problems": 495,
    "total_ranking_files": 495,
    "metrics": {
      "pass_at_1": 0.08080808080808081,
      "pass_at_5": 0.16565656565656567,
      "pass_at_10": 0.22626262626262628,
      "pass_at_20": 0.2787878787878788,
      "pass_at_50": 0.3575757575757576,
      "pass_at_100": 0.4101010101010101,
      "mrr": 0.12575320070629717,
      "ndcg_at_5": 0.0742703399662493,
      "ndcg_at_10": 0.07610354544403247,
      "ndcg_at_20": 0.08545560613055515,
      "avg_first_correct_position": 67.75353535353536,
      "median_first_correct_position": 101.0,
      "success_rate": 0.4101010101010101,
      "pass_at_2": 0.10707070707070707
    },
    "execution_summary": {
      "problems_with_passing_candidates": 203,
      "total_passing_candidates": 3640,
      "total_candidates": 49500
    }
  },
  "llm_judge_codellama-7b_humaneval": {
    "method": "llm_judge",
    "model": "codellama-7b",
    "dataset": "humaneval",
    "total_problems": 159,
    "total_ranking_files": 159,
    "metrics": {
      "pass_at_1": 0.24528301886792453,
      "pass_at_5": 0.5220125786163522,
      "pass_at_10": 0.610062893081761,
      "pass_at_20": 0.7044025157232704,
      "pass_at_50": 0.8238993710691824,
      "pass_at_100": 0.8616352201257862,
      "mrr": 0.3735898886481465,
      "ndcg_at_5": 0.25400940894283974,
      "ndcg_at_10": 0.2505315885986562,
      "ndcg_at_20": 0.2633230213902706,
      "avg_first_correct_position": 23.540880503144653,
      "median_first_correct_position": 5.0,
      "success_rate": 0.8616352201257862,
      "pass_at_2": 0.37735849056603776
    },
    "execution_summary": {
      "problems_with_passing_candidates": 137,
      "total_passing_candidates": 3536,
      "total_candidates": 15900
    }
  },
  "llm_judge_codellama-7b_mbpp": {
    "method": "llm_judge",
    "model": "codellama-7b",
    "dataset": "mbpp",
    "total_problems": 495,
    "total_ranking_files": 495,
    "metrics": {
      "pass_at_1": 0.07878787878787878,
      "pass_at_5": 0.19393939393939394,
      "pass_at_10": 0.2505050505050505,
      "pass_at_20": 0.296969696969697,
      "pass_at_50": 0.3595959595959596,
      "pass_at_100": 0.42424242424242425,
      "mrr": 0.13392944070397816,
      "ndcg_at_5": 0.08480326681287163,
      "ndcg_at_10": 0.090461109664239,
      "ndcg_at_20": 0.09885708659353652,
      "avg_first_correct_position": 66.71717171717172,
      "median_first_correct_position": 101.0,
      "success_rate": 0.42424242424242425,
      "pass_at_2": 0.1191919191919192
    },
    "execution_summary": {
      "problems_with_passing_candidates": 210,
      "total_passing_candidates": 4077,
      "total_candidates": 49500
    }
  },
  "llm_judge_codegen-2b_humaneval": {
    "method": "llm_judge",
    "model": "codegen-2b",
    "dataset": "humaneval",
    "total_problems": 159,
    "total_ranking_files": 159,
    "metrics": {
      "pass_at_1": 0.05660377358490566,
      "pass_at_5": 0.09433962264150944,
      "pass_at_10": 0.12578616352201258,
      "pass_at_20": 0.1509433962264151,
      "pass_at_50": 0.20754716981132076,
      "pass_at_100": 0.24528301886792453,
      "mrr": 0.07901603679599266,
      "ndcg_at_5": 0.04602682890547169,
      "ndcg_at_10": 0.048612841404952985,
      "ndcg_at_20": 0.05422399703019435,
      "avg_first_correct_position": 81.06918238993711,
      "median_first_correct_position": 101.0,
      "success_rate": 0.24528301886792453,
      "pass_at_2": 0.06918238993710692
    },
    "execution_summary": {
      "problems_with_passing_candidates": 39,
      "total_passing_candidates": 571,
      "total_candidates": 15900
    }
  },
  "llm_judge_codegen-2b_mbpp": {
    "method": "llm_judge",
    "model": "codegen-2b",
    "dataset": "mbpp",
    "total_problems": 495,
    "total_ranking_files": 495,
    "metrics": {
      "pass_at_1": 0.01616161616161616,
      "pass_at_5": 0.08080808080808081,
      "pass_at_10": 0.13535353535353536,
      "pass_at_20": 0.20202020202020202,
      "pass_at_50": 0.3434343434343434,
      "pass_at_100": 0.4383838383838384,
      "mrr": 0.05368792072250281,
      "ndcg_at_5": 0.02553768781417987,
      "ndcg_at_10": 0.03304019452867444,
      "ndcg_at_20": 0.043984850769836596,
      "avg_first_correct_position": 70.4020202020202,
      "median_first_correct_position": 101.0,
      "success_rate": 0.4383838383838384,
      "pass_at_2": 0.03232323232323232
    },
    "execution_summary": {
      "problems_with_passing_candidates": 217,
      "total_passing_candidates": 1188,
      "total_candidates": 49500
    }
  },
  "acecoder_rm_codet5-770m_humaneval": {
    "method": "acecoder_rm",
    "model": "codet5-770m",
    "dataset": "humaneval",
    "total_problems": 159,
    "total_ranking_files": 159,
    "metrics": {
      "pass_at_1": 0.12578616352201258,
      "pass_at_5": 0.25157232704402516,
      "pass_at_10": 0.2830188679245283,
      "pass_at_20": 0.3270440251572327,
      "pass_at_50": 0.37735849056603776,
      "pass_at_100": 0.4025157232704403,
      "mrr": 0.18454370380868068,
      "ndcg_at_5": 0.16054133788949687,
      "ndcg_at_10": 0.16681765584940078,
      "ndcg_at_20": 0.17701830629790277,
      "avg_first_correct_position": 65.24528301886792,
      "median_first_correct_position": 101.0,
      "success_rate": 0.4025157232704403,
      "pass_at_2": 0.18867924528301888
    },
    "execution_summary": {
      "problems_with_passing_candidates": 64,
      "total_passing_candidates": 1699,
      "total_candidates": 15900
    }
  },
  "acecoder_rm_codet5-770m_mbpp": {
    "method": "acecoder_rm",
    "model": "codet5-770m",
    "dataset": "mbpp",
    "total_problems": 495,
    "total_ranking_files": 495,
    "metrics": {
      "pass_at_1": 0.08080808080808081,
      "pass_at_5": 0.18787878787878787,
      "pass_at_10": 0.25656565656565655,
      "pass_at_20": 0.298989898989899,
      "pass_at_50": 0.3575757575757576,
      "pass_at_100": 0.4101010101010101,
      "mrr": 0.13517105925919828,
      "ndcg_at_5": 0.08536412602897318,
      "ndcg_at_10": 0.09272443906728522,
      "ndcg_at_20": 0.09846457738197291,
      "avg_first_correct_position": 66.98383838383839,
      "median_first_correct_position": 101.0,
      "success_rate": 0.4101010101010101,
      "pass_at_2": 0.12323232323232323
    },
    "execution_summary": {
      "problems_with_passing_candidates": 203,
      "total_passing_candidates": 3640,
      "total_candidates": 49500
    }
  },
  "acecoder_rm_codellama-7b_humaneval": {
    "method": "acecoder_rm",
    "model": "codellama-7b",
    "dataset": "humaneval",
    "total_problems": 159,
    "total_ranking_files": 159,
    "metrics": {
      "pass_at_1": 0.13836477987421383,
      "pass_at_5": 0.39622641509433965,
      "pass_at_10": 0.5283018867924528,
      "pass_at_20": 0.6477987421383647,
      "pass_at_50": 0.8238993710691824,
      "pass_at_100": 0.8616352201257862,
      "mrr": 0.2627605280609386,
      "ndcg_at_5": 0.17976596024153665,
      "ndcg_at_10": 0.19247388518669095,
      "ndcg_at_20": 0.21782212795476302,
      "avg_first_correct_position": 25.69811320754717,
      "median_first_correct_position": 9.0,
      "success_rate": 0.8616352201257862,
      "pass_at_2": 0.22641509433962265
    },
    "execution_summary": {
      "problems_with_passing_candidates": 137,
      "total_passing_candidates": 3536,
      "total_candidates": 15900
    }
  },
  "acecoder_rm_codellama-7b_mbpp": {
    "method": "acecoder_rm",
    "model": "codellama-7b",
    "dataset": "mbpp",
    "total_problems": 495,
    "total_ranking_files": 495,
    "metrics": {
      "pass_at_1": 0.09696969696969697,
      "pass_at_5": 0.18787878787878787,
      "pass_at_10": 0.22626262626262628,
      "pass_at_20": 0.2727272727272727,
      "pass_at_50": 0.3515151515151515,
      "pass_at_100": 0.42424242424242425,
      "mrr": 0.14170086653436018,
      "ndcg_at_5": 0.08879875516675306,
      "ndcg_at_10": 0.08841656767091431,
      "ndcg_at_20": 0.09521574569347235,
      "avg_first_correct_position": 67.21010101010101,
      "median_first_correct_position": 101.0,
      "success_rate": 0.42424242424242425,
      "pass_at_2": 0.1292929292929293
    },
    "execution_summary": {
      "problems_with_passing_candidates": 210,
      "total_passing_candidates": 4077,
      "total_candidates": 49500
    }
  },
  "acecoder_rm_codegen-2b_humaneval": {
    "method": "acecoder_rm",
    "model": "codegen-2b",
    "dataset": "humaneval",
    "total_problems": 159,
    "total_ranking_files": 159,
    "metrics": {
      "pass_at_1": 0.03773584905660377,
      "pass_at_5": 0.07547169811320754,
      "pass_at_10": 0.10062893081761007,
      "pass_at_20": 0.1761006289308176,
      "pass_at_50": 0.2389937106918239,
      "pass_at_100": 0.24528301886792453,
      "mrr": 0.0603308711032061,
      "ndcg_at_5": 0.035219306105893175,
      "ndcg_at_10": 0.03736659916787018,
      "ndcg_at_20": 0.04988307114874737,
      "avg_first_correct_position": 80.00628930817611,
      "median_first_correct_position": 101.0,
      "success_rate": 0.24528301886792453,
      "pass_at_2": 0.0440251572327044
    },
    "execution_summary": {
      "problems_with_passing_candidates": 39,
      "total_passing_candidates": 571,
      "total_candidates": 15900
    }
  },
  "acecoder_rm_codegen-2b_mbpp": {
    "method": "acecoder_rm",
    "model": "codegen-2b",
    "dataset": "mbpp",
    "total_problems": 495,
    "total_ranking_files": 495,
    "metrics": {
      "pass_at_1": 0.04040404040404041,
      "pass_at_5": 0.10303030303030303,
      "pass_at_10": 0.15757575757575756,
      "pass_at_20": 0.2,
      "pass_at_50": 0.3151515151515151,
      "pass_at_100": 0.4383838383838384,
      "mrr": 0.07761671648424417,
      "ndcg_at_5": 0.038357279484486195,
      "ndcg_at_10": 0.04460076509250989,
      "ndcg_at_20": 0.054323946879443405,
      "avg_first_correct_position": 71.40808080808081,
      "median_first_correct_position": 101.0,
      "success_rate": 0.4383838383838384,
      "pass_at_2": 0.06060606060606061
    },
    "execution_summary": {
      "problems_with_passing_candidates": 217,
      "total_passing_candidates": 1188,
      "total_candidates": 49500
    }
  }
}